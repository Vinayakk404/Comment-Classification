{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y29Wa1K4aQt2"
      },
      "source": [
        "# Installing dependencies\n",
        "\n",
        "\n",
        "*   Tensor flow is a deep learning library\n",
        "*   pandas to read the excel data\n",
        "\n",
        "*   Matplotlib for plotting\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BmBhto5noCm"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSlcIOpgZ575"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "rTGikpsiaMHA",
        "outputId": "16b5371d-f2d9-40b6-e317-9e1c12790af4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-81fc3bdd-37f8-4488-9afe-29dfda803a7e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-81fc3bdd-37f8-4488-9afe-29dfda803a7e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m   \"\"\"\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     result = _output.eval_js(\n\u001b[1;32m    151\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9dGjYHqfw0z"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('train.csv.zip',encoding = 'ISO-8859-1' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzKyKsgAiGbm"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "AEDjW3lpmuPU",
        "outputId": "7f545bc4-a794-44bd-d3cc-df5884c7423a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-05b71092c0e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sub' is not defined"
          ]
        }
      ],
      "source": [
        "sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BE1X4Q00iyl9",
        "outputId": "1c5f8066-08f3-4b88-baad-d5a287e5a284"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97c868a5-e38e-4300-87ab-3222020669df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97c868a5-e38e-4300-87ab-3222020669df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97c868a5-e38e-4300-87ab-3222020669df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97c868a5-e38e-4300-87ab-3222020669df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           id  comment_text  toxic  severe_toxic  obscene  threat  insult  \\\n",
              "0       False         False  False         False    False   False   False   \n",
              "1       False         False  False         False    False   False   False   \n",
              "2       False         False  False         False    False   False   False   \n",
              "3       False         False  False         False    False   False   False   \n",
              "4       False         False  False         False    False   False   False   \n",
              "...       ...           ...    ...           ...      ...     ...     ...   \n",
              "159566  False         False  False         False    False   False   False   \n",
              "159567  False         False  False         False    False   False   False   \n",
              "159568  False         False  False         False    False   False   False   \n",
              "159569  False         False  False         False    False   False   False   \n",
              "159570  False         False  False         False    False   False   False   \n",
              "\n",
              "        identity_hate  \n",
              "0               False  \n",
              "1               False  \n",
              "2               False  \n",
              "3               False  \n",
              "4               False  \n",
              "...               ...  \n",
              "159566          False  \n",
              "159567          False  \n",
              "159568          False  \n",
              "159569          False  \n",
              "159570          False  \n",
              "\n",
              "[159571 rows x 8 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub.isnull()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPPHodY4qw4G"
      },
      "source": [
        "Removing Null values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-BVVnBgm2Mt"
      },
      "outputs": [],
      "source": [
        "sub=sub.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X48C1HCFpaqR"
      },
      "outputs": [],
      "source": [
        "X=sub['comment_text']\n",
        "Y=sub[sub.columns[2:]].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POATLhYsp3Yh",
        "outputId": "0d93803d-95e3-4430-cf91-c35b74823a72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Explanation\\nWhy the edits made under my usern...\n",
              "1         D'aww! He matches this background colour I'm s...\n",
              "2         Hey man, I'm really not trying to edit war. It...\n",
              "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
              "4         You, sir, are my hero. Any chance you remember...\n",
              "                                ...                        \n",
              "159566    \":::::And for the second time of asking, when ...\n",
              "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
              "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
              "159569    And it looks like it was actually you who put ...\n",
              "159570    \"\\nAnd ... I really don't think you understand...\n",
              "Name: comment_text, Length: 159571, dtype: object"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwVb9wpH6IfV",
        "outputId": "594ba917-d3bb-4399-e0a0-30986c34a4f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaKtCuzIqtVa"
      },
      "source": [
        "Capital to lower case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvcb1UX3q0Ry"
      },
      "outputs": [],
      "source": [
        "X=X.apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwirxI_66Ov0",
        "outputId": "f962c4c7-b31a-4376-f53c-dce36aa80236"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         explanation\\nwhy the edits made under my usern...\n",
              "1         d'aww! he matches this background colour i'm s...\n",
              "2         hey man, i'm really not trying to edit war. it...\n",
              "3         \"\\nmore\\ni can't make any real suggestions on ...\n",
              "4         you, sir, are my hero. any chance you remember...\n",
              "                                ...                        \n",
              "159566    \":::::and for the second time of asking, when ...\n",
              "159567    you should be ashamed of yourself \\n\\nthat is ...\n",
              "159568    spitzer \\n\\numm, theres no actual article for ...\n",
              "159569    and it looks like it was actually you who put ...\n",
              "159570    \"\\nand ... i really don't think you understand...\n",
              "Name: comment_text, Length: 159571, dtype: object"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3jXKqB5fJNl"
      },
      "source": [
        "Remove new line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DaPWrqFrESh"
      },
      "outputs": [],
      "source": [
        "X=X.replace('\\n',' ', regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ijfHpyt6Swq",
        "outputId": "86f381d3-eafd-4674-dbd0-99332e9af87c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         explanation why the edits made under my userna...\n",
              "1         d'aww! he matches this background colour i'm s...\n",
              "2         hey man, i'm really not trying to edit war. it...\n",
              "3         \" more i can't make any real suggestions on im...\n",
              "4         you, sir, are my hero. any chance you remember...\n",
              "                                ...                        \n",
              "159566    \":::::and for the second time of asking, when ...\n",
              "159567    you should be ashamed of yourself   that is a ...\n",
              "159568    spitzer   umm, theres no actual article for pr...\n",
              "159569    and it looks like it was actually you who put ...\n",
              "159570    \" and ... i really don't think you understand....\n",
              "Name: comment_text, Length: 159571, dtype: object"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaO_c2qZerGY"
      },
      "source": [
        "Removing puntuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pOMubnSdEdL",
        "outputId": "96aa213e-70fa-4629-9f38-0dd7cc134113"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "X=X.str.replace(r'[^\\w\\s]+', ' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHjCdw6G6aHz",
        "outputId": "226aff4a-bb12-4a99-b6d3-1d73e8016381"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         explanation why the edits made under my userna...\n",
              "1         d aww  he matches this background colour i m s...\n",
              "2         hey man  i m really not trying to edit war  it...\n",
              "3           more i can t make any real suggestions on im...\n",
              "4         you  sir  are my hero  any chance you remember...\n",
              "                                ...                        \n",
              "159566     and for the second time of asking  when your ...\n",
              "159567    you should be ashamed of yourself   that is a ...\n",
              "159568    spitzer   umm  theres no actual article for pr...\n",
              "159569    and it looks like it was actually you who put ...\n",
              "159570      and   i really don t think you understand   ...\n",
              "Name: comment_text, Length: 159571, dtype: object"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ct1dI90qxzBj"
      },
      "source": [
        "# Stop Words removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTzkyajxyaCh",
        "outputId": "c16e6d40-87b9-44af-d779-043af7ebd08e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3YRArn3xx_j"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by6Xgozwx-Nr"
      },
      "outputs": [],
      "source": [
        "filtered_words = [word for word in X if word not in stopwords.words('english')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E057Lfab9i_U"
      },
      "outputs": [],
      "source": [
        "filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-Yv6SaZ9euI"
      },
      "outputs": [],
      "source": [
        "filtered_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7B9-v5Qhybi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KokUawnfu-J"
      },
      "outputs": [],
      "source": [
        "MAX_FEATURES=100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-kbgHVhgC8M"
      },
      "outputs": [],
      "source": [
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n",
        "                               output_sequence_length=1800,\n",
        "                               output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6gWXemNNgkrl"
      },
      "outputs": [],
      "source": [
        "vectorizer.adapt(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQgyZrNhgtuP"
      },
      "outputs": [],
      "source": [
        "vectorized_text = vectorizer(filtered_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgS5pKIfhHSa",
        "outputId": "ef8c132d-78d0-460a-95a2-5f9d570a6b99"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
              "array([[  682,    79,     2, ...,     0,     0,     0],\n",
              "       [  168, 16921,    52, ...,     0,     0,     0],\n",
              "       [  409,   420,     4, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [29526,  7303,  5175, ...,     0,     0,     0],\n",
              "       [    6,    11,   569, ...,     0,     0,     0],\n",
              "       [    6,     4,   139, ...,     0,     0,     0]])>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorized_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2jX3ArlhngS"
      },
      "source": [
        "Data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6IGqawSg8kc"
      },
      "outputs": [],
      "source": [
        "#MCSHBAP - map, chache, shuffle, batch, prefetch  from_tensor_slices, list_file\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, Y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)## Batch of 16\n",
        "dataset = dataset.prefetch(8) # helps bottlenecks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiXpT2XniV_w"
      },
      "source": [
        "Splitting test and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8FmHB65h46W"
      },
      "outputs": [],
      "source": [
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWA5bkoakzWs"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJm64J8jY5FT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdIFSuGBZXOx"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Flatten, LSTM\n",
        "from keras.layers import Input, GlobalMaxPool1D, Dropout\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.models import Model, Sequential\n",
        "from keras import optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI6dR4T957nU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRTfO30MY600"
      },
      "outputs": [],
      "source": [
        "##Linear stacks of layers where one layer leads to the next layer\n",
        "model = Sequential()\n",
        "##NOw we can add the layers\n",
        "##Turns positive integers (indexes) into dense vectors of fixed size. Max features is no. of embeddings per word. 32 is the length value\n",
        "model.add(Embedding(MAX_FEATURES+1,32))\n",
        "#creating an bidirectional LSTM LAYER\n",
        "model.add(Bidirectional(LSTM(50, return_sequences = True)))\n",
        "##This is done to reduce the number  of parameters to learn and the amount of computation performed in the networ\n",
        "model.add(GlobalMaxPool1D())\n",
        "##Add layers that re-center and re-scale Done to avoid  over-fitting of the data\n",
        "model.add(BatchNormalization())\n",
        "#nullifies the contribution of some neurons towards the next layer and leaves unmodified all others\n",
        "model.add(Dropout(0.1))\n",
        "##Feature extraction of fully completed layers\n",
        "## The RELU function returns 0 if the input is negative, but for any positive input, it returns that value back. \n",
        "model.add(Dense(50, activation = \"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(32, activation = \"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "##FINAL LAYERS Sigmoid guarentees output will be between 0 and 1\n",
        "model.add(Dense(6, activation = 'sigmoid'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjMs6soclAnl"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcW9UDd0lGXD",
        "outputId": "d9b9cabc-ff92-4dfb-fde2-9764fc0a5437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          3200032   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 100)        33200     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 100)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 100)              400       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1632      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 198       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,240,512\n",
            "Trainable params: 3,240,312\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WOSNWg67lKVN",
        "outputId": "f3ef7f67-e968-4ef3-f3c6-0bd9dcb4a919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "  40/6981 [..............................] - ETA: 3:00:53 - loss: 0.1902"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-9d182c3714ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(train, epochs=2, validation_data=val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ndruVs3mRko"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "dDVW8LifmUWE",
        "outputId": "2a557cfd-7026-49e2-91b0-b7bdf068c0ed"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8a25413e98dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'You suck i do not like you i hate you'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'vectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "input_text = vectorizer('You suck i do not like you i hate you')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov-CrHKLnLqH",
        "outputId": "2a897f8c-e8e6-4a93-c125-5cd3e94d5472"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',\n",
              "       'identity_hate'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub.columns[2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muW0KM4Pm56s",
        "outputId": "0292df62-e073-4097-b1c4-32c70a71b310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 662ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.9993943 , 0.27259955, 0.95686287, 0.03125585, 0.93831414,\n",
              "        0.21901862]], dtype=float32)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(np.expand_dims(input_text,0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "cqC-QxVgQTG7",
        "outputId": "44248046-7acb-4941-b845-5f2bca404606"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(8,5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggS57tzCGlzf"
      },
      "source": [
        "### Now lets predict for a batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh6LyBOarqT7"
      },
      "outputs": [],
      "source": [
        "batch_X, batch_y = test.as_numpy_iterator().next()\n",
        "res=(model.predict(batch_X) > 0.5).astype(int)\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STriN7RDIAJv",
        "outputId": "d8cc2827-6276-4a93-aaf5-1d09899e4087"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(16, 6)"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4da6G-0IJ7q"
      },
      "source": [
        "#Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Wc2W1uMINQN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uok4yqrIIPzp"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnP867-_IUvX"
      },
      "outputs": [],
      "source": [
        "for batch in test.as_numpy_iterator(): \n",
        "    # Unpack the batch \n",
        "    X_true, y_true = batch\n",
        "    # Make a prediction \n",
        "    yhat = model.predict(X_true)\n",
        "    \n",
        "    # Flatten the predictions\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "    \n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.update_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85NuH94HIfT5",
        "outputId": "3ba8d1ce-727e-47b3-8734-944cdacbd189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.8689053654670715, Recall:0.7603842616081238, Accuracy:0.4874624013900757\n"
          ]
        }
      ],
      "source": [
        "print(f'Precision: {pre.result().numpy()}, Recall:{re.result().numpy()}, Accuracy:{acc.result().numpy()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dcBYr8TINC6"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}